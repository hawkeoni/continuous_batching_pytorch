{
    "model": "Qwen/Qwen3-8B",
    "continuous_batching": true,
    "batch_size": 3,
    "max_prefix_len": 512,
    "max_new_tokens": 64,
    "dataset_size": 100,
    "fraction": 0.5
}